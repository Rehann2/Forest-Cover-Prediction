{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc71639d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:25:18.330450Z",
     "iopub.status.busy": "2022-01-04T22:25:18.329321Z",
     "iopub.status.idle": "2022-01-04T22:25:18.337470Z",
     "shell.execute_reply": "2022-01-04T22:25:18.338047Z",
     "shell.execute_reply.started": "2022-01-04T22:12:41.112052Z"
    },
    "papermill": {
     "duration": 0.037935,
     "end_time": "2022-01-04T22:25:18.338298",
     "exception": false,
     "start_time": "2022-01-04T22:25:18.300363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global variables for testing changes to this notebook quickly\n",
    "RANDOM_SEED = 0\n",
    "NUM_FOLDS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586cda3",
   "metadata": {
    "papermill": {
     "duration": 0.025269,
     "end_time": "2022-01-04T22:25:18.389611",
     "exception": false,
     "start_time": "2022-01-04T22:25:18.364342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Setup\n",
    "\n",
    "## 1. Imports\n",
    "\n",
    "Import all relevant libraries, models, evaluation metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a6bcc7c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-04T22:25:18.444291Z",
     "iopub.status.busy": "2022-01-04T22:25:18.443373Z",
     "iopub.status.idle": "2022-01-04T22:25:19.643991Z",
     "shell.execute_reply": "2022-01-04T22:25:19.644498Z",
     "shell.execute_reply.started": "2022-01-04T22:12:41.142148Z"
    },
    "papermill": {
     "duration": 1.229373,
     "end_time": "2022-01-04T22:25:19.644675",
     "exception": false,
     "start_time": "2022-01-04T22:25:18.415302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "import time\n",
    "import pyarrow\n",
    "import gc\n",
    "\n",
    "# Model & Evaluation\n",
    "from functools import partial\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e887c0",
   "metadata": {
    "papermill": {
     "duration": 0.025386,
     "end_time": "2022-01-04T22:25:19.695769",
     "exception": false,
     "start_time": "2022-01-04T22:25:19.670383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Load training/test data and encode the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df901978",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:25:19.752871Z",
     "iopub.status.busy": "2022-01-04T22:25:19.752160Z",
     "iopub.status.idle": "2022-01-04T22:25:22.619744Z",
     "shell.execute_reply": "2022-01-04T22:25:22.619240Z",
     "shell.execute_reply.started": "2022-01-04T22:12:42.595710Z"
    },
    "papermill": {
     "duration": 2.898479,
     "end_time": "2022-01-04T22:25:22.619925",
     "exception": false,
     "start_time": "2022-01-04T22:25:19.721446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load original data\n",
    "train = pd.read_csv(\"Data\\\\train.csv\")\n",
    "test = pd.read_csv(\"Data\\\\test-full.csv\")\n",
    "submission = pd.read_csv(\"Data\\\\full_submission.csv\")\n",
    "\n",
    "# Label Encode\n",
    "encoder = LabelEncoder()\n",
    "train[\"Cover_Type\"] = encoder.fit_transform(train[\"Cover_Type\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576f575",
   "metadata": {
    "papermill": {
     "duration": 0.025271,
     "end_time": "2022-01-04T22:25:22.670858",
     "exception": false,
     "start_time": "2022-01-04T22:25:22.645587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Scoring Function\n",
    "\n",
    "Function for performing k-fold cross-validation and averaging the test predictions across each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7771c57",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:25:22.734806Z",
     "iopub.status.busy": "2022-01-04T22:25:22.729719Z",
     "iopub.status.idle": "2022-01-04T22:25:22.738495Z",
     "shell.execute_reply": "2022-01-04T22:25:22.737782Z",
     "shell.execute_reply.started": "2022-01-04T22:12:46.014187Z"
    },
    "papermill": {
     "duration": 0.042348,
     "end_time": "2022-01-04T22:25:22.738637",
     "exception": false,
     "start_time": "2022-01-04T22:25:22.696289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    print(f'{NUM_FOLDS}-fold Cross Validation\\n')\n",
    "    \n",
    "    # Train/Test split\n",
    "    X_temp = train[features]\n",
    "    X_test = test[features]\n",
    "    y_temp = train['Cover_Type']\n",
    "\n",
    "    pca = PCA(n_components=30)\n",
    "    X_temp = pca.fit_transform(X_temp)\n",
    "    X_test = pca.transform(X_test)\n",
    "    \n",
    "    # Store the out-of-fold predictions\n",
    "    test_preds = np.zeros((X_test.shape[0],7))\n",
    "    oof_preds = np.zeros((X_temp.shape[0],))\n",
    "    fi_scores = np.zeros((X_temp.shape[1],))\n",
    "    scores, times = np.zeros(NUM_FOLDS), np.zeros(NUM_FOLDS)\n",
    "    \n",
    "    # Stratified k-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits = NUM_FOLDS, shuffle = True, random_state = RANDOM_SEED)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X_temp,y_temp)):\n",
    "       \n",
    "        # Training and Validation Sets\n",
    "        #X_train, X_valid = X_temp.iloc[train_idx], X_temp.iloc[valid_idx]\n",
    "        #y_train, y_valid = y_temp.iloc[train_idx], y_temp.iloc[valid_idx]\n",
    "        \n",
    "        #this is because of PCA\n",
    "        X_train, X_valid = X_temp[train_idx], X_temp[valid_idx]\n",
    "        y_train, y_valid = y_temp[train_idx], y_temp[valid_idx]\n",
    "\n",
    "\n",
    "        # Create model\n",
    "        start = time.time()\n",
    "        model = Pipeline([(\"preprocessing\", preprocessing.StandardScaler()),\n",
    "                          #(\"gradient_boosting\", XGBClassifier(tree_method = 'gpu_hist', learning_rate=0.3, n_estimators=200, max_depth=15))])\n",
    "                          (\"gradient_boosting\", ExtraTreesClassifier(n_estimators = 118,\n",
    "                                                                     min_samples_split = 2,\n",
    "                                                                     max_features = 14,\n",
    "                                                                     random_state = RANDOM_SEED,\n",
    "                                                                     n_jobs = -1))])\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # validation/holdout predictions\n",
    "        valid_preds = np.ravel(model.predict(X_valid))\n",
    "        oof_preds[valid_idx] = valid_preds\n",
    "        test_preds += model.predict_proba(X_test)\n",
    "\n",
    "        # Save scores and times\n",
    "        scores[fold] = accuracy_score(y_valid, valid_preds)\n",
    "        end = time.time()\n",
    "        times[fold] = end-start\n",
    "        print(f'Fold {fold}: {round(scores[fold], 5)} in {round(times[fold], 2)}s')\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    test_preds = np.argmax(test_preds, axis = 1)\n",
    "    print('\\nModel: '+model.__class__.__name__)\n",
    "    print(\"Train Accuracy:\", round(scores.mean(), 5))\n",
    "    print(f'Training Time: {round(times.sum(), 2)}s')\n",
    "    \n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ebc57d",
   "metadata": {
    "papermill": {
     "duration": 0.029417,
     "end_time": "2022-01-04T22:26:40.757629",
     "exception": false,
     "start_time": "2022-01-04T22:26:40.728212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# General Feature Engineering\n",
    "\n",
    "In this section we consider several new features generated from the original data. Check out the following notebooks/discussions for more information and original sources for some of these features:\n",
    "\n",
    "* Notebook: [Two models Random Forests](https://www.kaggle.com/shouldnotbehere/two-models-random-forests)\n",
    "* Notebook: [my_first_submission](https://www.kaggle.com/jianyu/my-first-submission)\n",
    "* Discussion: [TPS12 feature engineering](https://www.kaggle.com/c/tabular-playground-series-dec-2021/discussion/293612)\n",
    "\n",
    "The features included below are those from the previous sources which resulted in improved CV accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a610a132",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:40.832424Z",
     "iopub.status.busy": "2022-01-04T22:26:40.831405Z",
     "iopub.status.idle": "2022-01-04T22:26:40.834131Z",
     "shell.execute_reply": "2022-01-04T22:26:40.833621Z",
     "shell.execute_reply.started": "2022-01-04T22:14:17.204662Z"
    },
    "papermill": {
     "duration": 0.046696,
     "end_time": "2022-01-04T22:26:40.834267",
     "exception": false,
     "start_time": "2022-01-04T22:26:40.787571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def misc_features(data):\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Use float64 for calculations\n",
    "    for col, dtype in df.dtypes.iteritems():\n",
    "        if dtype.name.startswith('float'):\n",
    "            df[col] = df[col].astype('float64')\n",
    "            \n",
    "    # Interaction Terms\n",
    "    # Create a new column with the natural logarithm of the horizontal distance to roadways plus 1\n",
    "    df['Horizontal_Distance_To_Roadways_Log'] = [math.log(v+1) for v in df['Horizontal_Distance_To_Roadways']]\n",
    "    # Create a new column with the difference between elevation and vertical distance to hydrology\n",
    "    df['Water Elevation'] = df['Elevation'] - df['Vertical_Distance_To_Hydrology']\n",
    "    # Create a new column with the sum of horizontal distance to hydrology and horizontal distance to fire points\n",
    "    df['Hydro_Fire_1'] = df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Fire_Points']\n",
    "    # Create a new column with the absolute difference between horizontal distance to hydrology and horizontal distance to fire points\n",
    "    df['Hydro_Fire_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Fire_Points'])\n",
    "    # Create a new column with the absolute sum of horizontal distance to hydrology and horizontal distance to roadways\n",
    "    df['Hydro_Road_1'] = abs(df['Horizontal_Distance_To_Hydrology'] + df['Horizontal_Distance_To_Roadways'])\n",
    "    # Create a new column with the absolute difference between horizontal distance to hydrology and horizontal distance to roadways\n",
    "    df['Hydro_Road_2'] = abs(df['Horizontal_Distance_To_Hydrology'] - df['Horizontal_Distance_To_Roadways'])\n",
    "    # Create a new column with the absolute sum of horizontal distance to fire points and horizontal distance to roadways\n",
    "    df['Fire_Road_1'] = abs(df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Roadways'])\n",
    "    # Create a new column with the absolute difference between horizontal distance to fire points and horizontal distance to roadways\n",
    "    df['Fire_Road_2'] = abs(df['Horizontal_Distance_To_Fire_Points'] - df['Horizontal_Distance_To_Roadways'])\n",
    "    # Create a new column with the product of horizontal distance to roadways and elevation\n",
    "    df['EHiElv'] = df['Horizontal_Distance_To_Roadways'] * df['Elevation']\n",
    "    # Create a new column with the difference between elevation and vertical distance to hydrology\n",
    "    df['EVDtH'] = df.Elevation - df.Vertical_Distance_To_Hydrology\n",
    "    # Create a new column with the elevation minus 0.2 times horizontal distance to hydrology\n",
    "    df['EHDtH'] = df.Elevation - df.Horizontal_Distance_To_Hydrology * 0.2\n",
    "    # Create a new column with the sum of elevation, horizontal distance to roadways, horizontal distance to fire points, and horizontal distance to hydrology\n",
    "    df['Elev_3Horiz'] = df['Elevation'] + df['Horizontal_Distance_To_Roadways']  + df['Horizontal_Distance_To_Fire_Points'] + df['Horizontal_Distance_To_Hydrology']\n",
    "    # Create a new column with the sum of elevation and horizontal distance to roadways\n",
    "    df['Elev_Road_1'] = df['Elevation'] + df['Horizontal_Distance_To_Roadways']\n",
    "    # Create a new column with the difference between elevation and horizontal distance to roadways\n",
    "    df['Elev_Road_2'] = df['Elevation'] - df['Horizontal_Distance_To_Roadways']\n",
    "    # Create a new column with the sum of elevation and horizontal distance to fire points\n",
    "    df['Elev_Fire_1'] = df['Elevation'] + df['Horizontal_Distance_To_Fire_Points']\n",
    "    # Create a new column with the difference between elevation and horizontal distance to fire points\n",
    "    df['Elev_Fire_2'] = df['Elevation'] - df['Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "    # Fill NA\n",
    "    df.fillna(0, inplace = True)\n",
    "    \n",
    "    # Downcast variables\n",
    "    for col, dtype in df.dtypes.iteritems():\n",
    "        if dtype.name.startswith('int'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast ='integer')\n",
    "        elif dtype.name.startswith('float'):\n",
    "            df[col] = pd.to_numeric(df[col], downcast ='float')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "855588f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:40.899142Z",
     "iopub.status.busy": "2022-01-04T22:26:40.898331Z",
     "iopub.status.idle": "2022-01-04T22:26:45.498247Z",
     "shell.execute_reply": "2022-01-04T22:26:45.497652Z",
     "shell.execute_reply.started": "2022-01-04T22:14:17.222641Z"
    },
    "papermill": {
     "duration": 4.634113,
     "end_time": "2022-01-04T22:26:45.498425",
     "exception": false,
     "start_time": "2022-01-04T22:26:40.864312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\teuta\\AppData\\Local\\Temp\\ipykernel_9164\\876412685.py:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col, dtype in df.dtypes.iteritems():\n",
      "C:\\Users\\teuta\\AppData\\Local\\Temp\\ipykernel_9164\\876412685.py:47: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col, dtype in df.dtypes.iteritems():\n",
      "C:\\Users\\teuta\\AppData\\Local\\Temp\\ipykernel_9164\\876412685.py:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col, dtype in df.dtypes.iteritems():\n",
      "C:\\Users\\teuta\\AppData\\Local\\Temp\\ipykernel_9164\\876412685.py:47: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for col, dtype in df.dtypes.iteritems():\n"
     ]
    }
   ],
   "source": [
    "# misc feature engineering\n",
    "train = misc_features(train)\n",
    "test = misc_features(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32b5bc2c",
   "metadata": {
    "papermill": {
     "duration": 0.029723,
     "end_time": "2022-01-04T22:26:45.559358",
     "exception": false,
     "start_time": "2022-01-04T22:26:45.529635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Soil Type Feature Engineering\n",
    "\n",
    "In this section we consider several new features based on the soil-type variables:\n",
    "\n",
    "0. Categorical Encoding (40 columns -> 1 column)\n",
    "1. Climatic Zone\n",
    "2. Geologic Zone\n",
    "3. Surface Cover\n",
    "4. Rock Size\n",
    "5. Interaction Terms\n",
    "6. Drop Original\n",
    "\n",
    "## ELU Codes\n",
    "\n",
    "From the original data description, the soil type number is based on the USFS Ecological Landtype Units (ELUs). The ELU code contains further information about the soils including the climatic zone and geologic zone. Furthermore, each ELU code comes with a brief description from which we can extract further information about the surface cover (by rocks/boulders) and rock size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96c339f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:45.622915Z",
     "iopub.status.busy": "2022-01-04T22:26:45.622239Z",
     "iopub.status.idle": "2022-01-04T22:26:45.629164Z",
     "shell.execute_reply": "2022-01-04T22:26:45.629693Z",
     "shell.execute_reply.started": "2022-01-04T22:14:24.764788Z"
    },
    "papermill": {
     "duration": 0.040271,
     "end_time": "2022-01-04T22:26:45.629873",
     "exception": false,
     "start_time": "2022-01-04T22:26:45.589602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mapping soil type to ELU code\n",
    "ELU_CODE = {\n",
    "    1:2702,2:2703,3:2704,4:2705,5:2706,6:2717,7:3501,8:3502,9:4201,\n",
    "    10:4703,11:4704,12:4744,13:4758,14:5101,15:5151,16:6101,17:6102,\n",
    "    18:6731,19:7101,20:7102,21:7103,22:7201,23:7202,24:7700,25:7701,\n",
    "    26:7702,27:7709,28:7710,29:7745,30:7746,31:7755,32:7756,33:7757,\n",
    "    34:7790,35:8703,36:8707,37:8708,38:8771,39:8772,40:8776\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693bd8d",
   "metadata": {
    "papermill": {
     "duration": 0.029672,
     "end_time": "2022-01-04T22:26:45.689699",
     "exception": false,
     "start_time": "2022-01-04T22:26:45.660027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0. Categorical Encoding\n",
    "\n",
    "**Note:** Soil type is a single variable which has been one-hot encoded presumably to behave nicely with a neural network. Generally, tree-based models work better without explicit one-hot encoding, so we will reverse engineer the soil type. We will eventually drop the original soil type columns which has the added effect of significantly reducing the total number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad4f65c0",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:45.752813Z",
     "iopub.status.busy": "2022-01-04T22:26:45.752204Z",
     "iopub.status.idle": "2022-01-04T22:26:45.756084Z",
     "shell.execute_reply": "2022-01-04T22:26:45.756552Z",
     "shell.execute_reply.started": "2022-01-04T22:14:24.774829Z"
    },
    "papermill": {
     "duration": 0.037043,
     "end_time": "2022-01-04T22:26:45.756705",
     "exception": false,
     "start_time": "2022-01-04T22:26:45.719662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode soil type ordinally\n",
    "def categorical_encoding(input_df):\n",
    "    data = input_df.copy()\n",
    "    data['Soil_Type'] = 0\n",
    "    for i in range(1,41):\n",
    "        data['Soil_Type'] += i*data[f'Soil_Type{i}']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad7c7c53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:45.821423Z",
     "iopub.status.busy": "2022-01-04T22:26:45.820773Z",
     "iopub.status.idle": "2022-01-04T22:26:46.016927Z",
     "shell.execute_reply": "2022-01-04T22:26:46.016284Z",
     "shell.execute_reply.started": "2022-01-04T22:14:24.790191Z"
    },
    "papermill": {
     "duration": 0.230644,
     "end_time": "2022-01-04T22:26:46.017074",
     "exception": false,
     "start_time": "2022-01-04T22:26:45.786430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Encode soil type\n",
    "train = categorical_encoding(train)\n",
    "test = categorical_encoding(test)\n",
    "\n",
    "# Original soil features\n",
    "soil_features = [f'Soil_Type{i}' for i in range(1,41)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dcc09f",
   "metadata": {
    "papermill": {
     "duration": 0.029437,
     "end_time": "2022-01-04T22:26:46.077768",
     "exception": false,
     "start_time": "2022-01-04T22:26:46.048331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Climatic Zone (Ordinal Variable)\n",
    "\n",
    "We create a feature based on the climatic zone of the soil. This can be determined by the first digit of the ELU code. Note that the climatic zone has a natural ordering:\n",
    "\n",
    "1. lower montane dry\n",
    "2. lower montane\n",
    "3. montane dry\n",
    "4. montane\n",
    "5. montane dry and montane\n",
    "6. montane and subalpine\n",
    "7. subalpine\n",
    "8. alpine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8aa54744",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:46.142748Z",
     "iopub.status.busy": "2022-01-04T22:26:46.142131Z",
     "iopub.status.idle": "2022-01-04T22:26:46.143588Z",
     "shell.execute_reply": "2022-01-04T22:26:46.144179Z",
     "shell.execute_reply.started": "2022-01-04T22:14:25.047733Z"
    },
    "papermill": {
     "duration": 0.036919,
     "end_time": "2022-01-04T22:26:46.144424",
     "exception": false,
     "start_time": "2022-01-04T22:26:46.107505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def climatic_zone(input_df):\n",
    "    df = input_df.copy()\n",
    "    df['Climatic_Zone'] = input_df['Soil_Type'].apply(\n",
    "        lambda x: int(str(ELU_CODE[x])[0])\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f40b6b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:46.207223Z",
     "iopub.status.busy": "2022-01-04T22:26:46.206589Z",
     "iopub.status.idle": "2022-01-04T22:26:46.814607Z",
     "shell.execute_reply": "2022-01-04T22:26:46.813895Z",
     "shell.execute_reply.started": "2022-01-04T22:14:25.054853Z"
    },
    "papermill": {
     "duration": 0.640351,
     "end_time": "2022-01-04T22:26:46.814759",
     "exception": false,
     "start_time": "2022-01-04T22:26:46.174408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Climatic Zone\n",
    "train = climatic_zone(train)\n",
    "test = climatic_zone(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba96bcb",
   "metadata": {
    "papermill": {
     "duration": 0.030608,
     "end_time": "2022-01-04T22:26:46.876486",
     "exception": false,
     "start_time": "2022-01-04T22:26:46.845878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Geologic Zone (Nominal Variable)\n",
    "\n",
    "This is another feature that comes directly from the ELU code. The geologic zone is determined by the second digit in the ELU code. Unlike the climatic zone, the geologic zone has no natural ordering:\n",
    "\n",
    "1. alluvium\n",
    "2. glacial\n",
    "3. shale\n",
    "4. sandstone\n",
    "5. mixed sedimentary\n",
    "6. unspecified in the USFS ELU Survey\n",
    "7. igneous and metamorphic\n",
    "8. volcanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "356ebef8",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:46.942361Z",
     "iopub.status.busy": "2022-01-04T22:26:46.939942Z",
     "iopub.status.idle": "2022-01-04T22:26:46.945033Z",
     "shell.execute_reply": "2022-01-04T22:26:46.944533Z",
     "shell.execute_reply.started": "2022-01-04T22:14:25.689695Z"
    },
    "papermill": {
     "duration": 0.038456,
     "end_time": "2022-01-04T22:26:46.945173",
     "exception": false,
     "start_time": "2022-01-04T22:26:46.906717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def geologic_zone(input_df):\n",
    "    df = input_df.copy()\n",
    "    df['Geologic_Zone'] = input_df['Soil_Type'].apply(\n",
    "        lambda x: int(str(ELU_CODE[x])[1])\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84a4fc99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:47.010187Z",
     "iopub.status.busy": "2022-01-04T22:26:47.009493Z",
     "iopub.status.idle": "2022-01-04T22:26:47.616775Z",
     "shell.execute_reply": "2022-01-04T22:26:47.616235Z",
     "shell.execute_reply.started": "2022-01-04T22:14:25.700163Z"
    },
    "papermill": {
     "duration": 0.641925,
     "end_time": "2022-01-04T22:26:47.616916",
     "exception": false,
     "start_time": "2022-01-04T22:26:46.974991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Geologic Zone\n",
    "train = geologic_zone(train)\n",
    "test = geologic_zone(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c335442",
   "metadata": {
    "papermill": {
     "duration": 0.029535,
     "end_time": "2022-01-04T22:26:47.676253",
     "exception": false,
     "start_time": "2022-01-04T22:26:47.646718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Surface Cover (Ordinal Variable)\n",
    "\n",
    "This feature is also based on the ELU code and the original data description for each soil type. Note that not all of the soil types have a description of their surface cover. According to the [USDA reference](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/ref/?cid=nrcs142p2_054253#surface_fragments) on soil profiling:\n",
    "\n",
    "1. (Stony/Bouldery) — Stones or boulders cover 0.01 to less than 0.1 percent of the surface. The smallest stones are at least 8 meters apart; the smallest boulders are at least 20 meters apart.\n",
    "\n",
    "2. (Very Stony/Very Bouldery) — Stones or boulders cover 0.1 to less than 3 percent of the surface. The smallest stones are not less than 1 meter apart; the smallest boulders are not less than 3 meters apart.\n",
    "\n",
    "3. (Extremely Stony/Extremely Bouldery) — Stones or boulders cover 3 to less than 15 percent of the surface. The smallest stones are as little as 0.5 meter apart; the smallest boulders are as little as 1 meter apart.\n",
    "\n",
    "4. (Rubbly) — Stones or boulders cover 15 to less than 50 percent of the surface. The smallest stones are as little as 0.3 meter apart; the smallest boulders are as little as 0.5 meter apart. In most places it is possible to step from stone to stone or jump from boulder to boulder without touching the soil.\n",
    "\n",
    "5. (Very Rubbly) — Stones or boulders appear to be nearly continuous and cover 50 percent or more of the surface. The smallest stones are less than 0.03 meter apart; the smallest boulders are less than 0.05 meter apart. Classifiable soil is among the rock fragments, and plant growth is possible.\n",
    "\n",
    "If no description of the surface cover is given, we give it a value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb8a854f",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:47.745333Z",
     "iopub.status.busy": "2022-01-04T22:26:47.744442Z",
     "iopub.status.idle": "2022-01-04T22:26:47.748316Z",
     "shell.execute_reply": "2022-01-04T22:26:47.747649Z",
     "shell.execute_reply.started": "2022-01-04T22:14:26.408266Z"
    },
    "papermill": {
     "duration": 0.042414,
     "end_time": "2022-01-04T22:26:47.748457",
     "exception": false,
     "start_time": "2022-01-04T22:26:47.706043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def surface_cover(input_df):\n",
    "    # Group IDs\n",
    "    no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "    stony = [6,12]\n",
    "    very_stony = [2,9,18,26]\n",
    "    extremely_stony = [1,22,24,25,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "    rubbly = [3,4,5,10,11,13]\n",
    "\n",
    "    # Create dictionary\n",
    "    surface_cover = {i:0 for i in no_desc}\n",
    "    surface_cover.update({i:1 for i in stony})\n",
    "    surface_cover.update({i:2 for i in very_stony})\n",
    "    surface_cover.update({i:3 for i in extremely_stony})\n",
    "    surface_cover.update({i:4 for i in rubbly})\n",
    "    \n",
    "    # Create Feature\n",
    "    df = input_df.copy()\n",
    "    df['Surface_Cover'] = input_df['Soil_Type'].apply(\n",
    "        lambda x: surface_cover[x]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2760d405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:47.812533Z",
     "iopub.status.busy": "2022-01-04T22:26:47.811853Z",
     "iopub.status.idle": "2022-01-04T22:26:48.149689Z",
     "shell.execute_reply": "2022-01-04T22:26:48.149134Z",
     "shell.execute_reply.started": "2022-01-04T22:14:26.421514Z"
    },
    "papermill": {
     "duration": 0.371502,
     "end_time": "2022-01-04T22:26:48.149836",
     "exception": false,
     "start_time": "2022-01-04T22:26:47.778334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Surface Cover\n",
    "train = surface_cover(train)\n",
    "test = surface_cover(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce16b5f",
   "metadata": {
    "papermill": {
     "duration": 0.029756,
     "end_time": "2022-01-04T22:26:48.209600",
     "exception": false,
     "start_time": "2022-01-04T22:26:48.179844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Rock Size (Nominal)\n",
    "\n",
    "The final soil type feature we consider is rock size. This is also determined from the ELU code, the original data description and the [USFS soil profiling reference](https://www.nrcs.usda.gov/wps/portal/nrcs/detail/soils/ref/?cid=nrcs142p2_054253#fragments):\n",
    "\n",
    "1. Stones\n",
    "2. Boulders\n",
    "3. Rubble\n",
    "\n",
    "If the soil type description has no mention of rock size, we give it a default value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f864232f",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:48.280169Z",
     "iopub.status.busy": "2022-01-04T22:26:48.279134Z",
     "iopub.status.idle": "2022-01-04T22:26:48.281090Z",
     "shell.execute_reply": "2022-01-04T22:26:48.281613Z",
     "shell.execute_reply.started": "2022-01-04T22:14:26.871489Z"
    },
    "papermill": {
     "duration": 0.041079,
     "end_time": "2022-01-04T22:26:48.281784",
     "exception": false,
     "start_time": "2022-01-04T22:26:48.240705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rock_size(input_df):\n",
    "    \n",
    "    # Group IDs\n",
    "    no_desc = [7,8,14,15,16,17,19,20,21,23,35]\n",
    "    stones = [1,2,6,9,12,18,24,25,26,27,28,29,30,31,32,33,34,36,37,38,39,40]\n",
    "    boulders = [22]\n",
    "    rubble = [3,4,5,10,11,13]\n",
    "\n",
    "    # Create dictionary\n",
    "    rock_size = {i:0 for i in no_desc}\n",
    "    rock_size.update({i:1 for i in stones})\n",
    "    rock_size.update({i:2 for i in boulders})\n",
    "    rock_size.update({i:3 for i in rubble})\n",
    "    \n",
    "    df = input_df.copy()\n",
    "    df['Rock_Size'] = input_df['Soil_Type'].apply(\n",
    "        lambda x: rock_size[x]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47440868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:48.345937Z",
     "iopub.status.busy": "2022-01-04T22:26:48.345303Z",
     "iopub.status.idle": "2022-01-04T22:26:48.684704Z",
     "shell.execute_reply": "2022-01-04T22:26:48.685228Z",
     "shell.execute_reply.started": "2022-01-04T22:14:26.884571Z"
    },
    "papermill": {
     "duration": 0.373815,
     "end_time": "2022-01-04T22:26:48.685409",
     "exception": false,
     "start_time": "2022-01-04T22:26:48.311594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Surface Cover\n",
    "train = rock_size(train)\n",
    "test = rock_size(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b3e5d",
   "metadata": {
    "papermill": {
     "duration": 0.029598,
     "end_time": "2022-01-04T22:26:48.745277",
     "exception": false,
     "start_time": "2022-01-04T22:26:48.715679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Soil Type Interactions\n",
    "\n",
    "In this section we form some interaction features using soil type and these new soil-type derived features. We include only those features which resulted in improved CV accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40511690",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:48.809162Z",
     "iopub.status.busy": "2022-01-04T22:26:48.808446Z",
     "iopub.status.idle": "2022-01-04T22:26:48.816272Z",
     "shell.execute_reply": "2022-01-04T22:26:48.816807Z",
     "shell.execute_reply.started": "2022-01-04T22:14:27.332060Z"
    },
    "papermill": {
     "duration": 0.041564,
     "end_time": "2022-01-04T22:26:48.816986",
     "exception": false,
     "start_time": "2022-01-04T22:26:48.775422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def soiltype_interactions(data):\n",
    "    df = data.copy()\n",
    "            \n",
    "    # Important Soil Types\n",
    "    df['Soil_12_32'] = df['Soil_Type32'] + df['Soil_Type12']\n",
    "    df['Soil_Type23_22_32_33'] = df['Soil_Type23'] + df['Soil_Type22'] + df['Soil_Type32'] + df['Soil_Type33']\n",
    "    \n",
    "    # Soil Type Interactions\n",
    "    df['Soil29_Area1'] = df['Soil_Type29'] + df['Wilderness_Area1']\n",
    "    df['Soil3_Area4'] = df['Wilderness_Area4'] + df['Soil_Type3']\n",
    "    \n",
    "    #  New Feature Interactions\n",
    "    df['Climate_Area2'] = df['Wilderness_Area2']*df['Climatic_Zone'] \n",
    "    df['Climate_Area4'] = df['Wilderness_Area4']*df['Climatic_Zone'] \n",
    "    df['Rock_Area1'] = df['Wilderness_Area1']*df['Rock_Size']    \n",
    "    df['Rock_Area3'] = df['Wilderness_Area3']*df['Rock_Size']  \n",
    "    df['Surface_Area1'] = df['Wilderness_Area1']*df['Surface_Cover'] \n",
    "    df['Surface_Area2'] = df['Wilderness_Area2']*df['Surface_Cover']   \n",
    "    df['Surface_Area4'] = df['Wilderness_Area4']*df['Surface_Cover'] \n",
    "    \n",
    "    # Fill NA\n",
    "    df.fillna(0, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b74faac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:48.879996Z",
     "iopub.status.busy": "2022-01-04T22:26:48.879368Z",
     "iopub.status.idle": "2022-01-04T22:26:49.006286Z",
     "shell.execute_reply": "2022-01-04T22:26:49.005594Z",
     "shell.execute_reply.started": "2022-01-04T22:14:27.347881Z"
    },
    "papermill": {
     "duration": 0.15941,
     "end_time": "2022-01-04T22:26:49.006428",
     "exception": false,
     "start_time": "2022-01-04T22:26:48.847018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Surface Cover\n",
    "train = soiltype_interactions(train)\n",
    "test = soiltype_interactions(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c952123",
   "metadata": {
    "papermill": {
     "duration": 0.029751,
     "end_time": "2022-01-04T22:26:49.066639",
     "exception": false,
     "start_time": "2022-01-04T22:26:49.036888",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Drop Columns\n",
    "\n",
    "Finally, we drop the original soil type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "91768d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:49.133792Z",
     "iopub.status.busy": "2022-01-04T22:26:49.133144Z",
     "iopub.status.idle": "2022-01-04T22:26:49.163676Z",
     "shell.execute_reply": "2022-01-04T22:26:49.164216Z",
     "shell.execute_reply.started": "2022-01-04T22:14:27.636345Z"
    },
    "papermill": {
     "duration": 0.067921,
     "end_time": "2022-01-04T22:26:49.164384",
     "exception": false,
     "start_time": "2022-01-04T22:26:49.096463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop original soil features\n",
    "train.drop(columns = soil_features, inplace = True)\n",
    "test.drop(columns = soil_features, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf30c3",
   "metadata": {
    "papermill": {
     "duration": 0.029524,
     "end_time": "2022-01-04T22:26:49.223875",
     "exception": false,
     "start_time": "2022-01-04T22:26:49.194351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4b63b3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def Gridsearchcv():\n",
    "    X_train = train[features]\n",
    "    X_test = test[features]\n",
    "    y_train = train['Cover_Type']\n",
    "\n",
    "    model = Pipeline([(\"preprocessing\", preprocessing.StandardScaler()),\n",
    "                      (\"gradient_boosting\", XGBClassifier(tree_method = 'gpu_hist'))])\n",
    "    \n",
    "    param_grid = {\n",
    "    \"gradient_boosting__learning_rate\": [0.1, 0.3],\n",
    "    \"gradient_boosting__n_estimators\": [200, 500],\n",
    "    \"gradient_boosting__max_depth\": [10, 15],\n",
    "    \"gradient_boosting__colsample_bytree\": [0.5, 1],\n",
    "    }\n",
    "\n",
    "    # Define the GridSearchCV object\n",
    "    grid_search = GridSearchCV(\n",
    "        model, param_grid=param_grid, cv=5, n_jobs=1, verbose=3\n",
    "    )\n",
    "    \n",
    "    # Fit the GridSearchCV object to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afa4eaa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-04T22:26:49.287610Z",
     "iopub.status.busy": "2022-01-04T22:26:49.286988Z",
     "iopub.status.idle": "2022-01-04T22:27:58.900160Z",
     "shell.execute_reply": "2022-01-04T22:27:58.899553Z",
     "shell.execute_reply.started": "2022-01-04T22:14:27.687757Z"
    },
    "papermill": {
     "duration": 69.646053,
     "end_time": "2022-01-04T22:27:58.900320",
     "exception": false,
     "start_time": "2022-01-04T22:26:49.254267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12-fold Cross Validation\n",
      "\n",
      "Fold 0: 0.89603 in 4.59s\n",
      "Fold 1: 0.89444 in 5.34s\n",
      "Fold 2: 0.88413 in 4.94s\n",
      "Fold 3: 0.89444 in 4.79s\n",
      "Fold 4: 0.86905 in 4.55s\n",
      "Fold 5: 0.88095 in 4.43s\n",
      "Fold 6: 0.89444 in 4.29s\n",
      "Fold 7: 0.90159 in 4.39s\n",
      "Fold 8: 0.88651 in 4.46s\n",
      "Fold 9: 0.88889 in 4.16s\n",
      "Fold 10: 0.88413 in 3.91s\n",
      "Fold 11: 0.88889 in 3.79s\n",
      "\n",
      "Model: Pipeline\n",
      "Train Accuracy: 0.88862\n",
      "Training Time: 53.65s\n"
     ]
    }
   ],
   "source": [
    "# Submission with feature engineering\n",
    "features = [x for x in train.columns if x not in ['Id', 'Cover_Type']] \n",
    "submission['Cover_Type'] = encoder.inverse_transform(\n",
    "    train_model()\n",
    ")\n",
    "#Gridsearchcv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_full_feature_engineering_extratrees.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 171.072648,
   "end_time": "2022-01-04T22:27:59.645792",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-04T22:25:08.573144",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
